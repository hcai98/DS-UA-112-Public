{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "intro",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Project 1: Trump, Twitter, and Text\n",
    "\n",
    "In this project, we will work with the Twitter API in order to analyze Donald Trump's tweets.\n",
    "\n",
    "**The project is due 11:59pm Sunday, October 20**\n",
    "\n",
    "If you find yourself getting frustrated or stuck on one problem for too long, we suggest coming into office hours and working with friends in the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "import",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell to set up your notebook\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import json\n",
    "\n",
    "# Ensure that Pandas shows at least 280 characters in columns, so we can see full tweets\n",
    "pd.set_option('max_colwidth', 280)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "2a-x",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "start-pt-desc",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The starting point and a key aspect of any data science project is getting the data. To get Twitter data, Twitter conveniently provides a developer API using which we can scrape data. More on that will follow in the coming discussions!\n",
    "\n",
    "For now, we've made life easier for you by providing the data.\n",
    "\n",
    "Start by running the following cells, which will download and then load Donald Trump's most recent tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "2axfetch",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "from utils import fetch_and_cache\n",
    "data_url = 'https://cims.nyu.edu/~policast/recent_tweets.json'\n",
    "file_name = 'realdonaldtrump_recent_tweets.json'\n",
    "\n",
    "dest_path = fetch_and_cache(data_url=data_url, file=file_name)\n",
    "print(f'Located at {dest_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loadtweets2ax",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def load_tweets(path):\n",
    "    \"\"\"Loads tweets that have previously been saved.\n",
    "    \n",
    "    Calling load_tweets(path) after save_tweets(tweets, path)\n",
    "    will produce the same list of tweets.\n",
    "    \n",
    "    Args:\n",
    "        path (str): The place where the tweets were be saved.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of Dictionary objects, each representing one tweet.\"\"\"\n",
    "    \n",
    "    with open(path, \"rb\") as f:\n",
    "        import json\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "call-load-tweets-2ax",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump_tweets = load_tweets(dest_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "2ax-conclusion",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "If everything is working correctly correctly this should load roughly the last 3000 tweets by `realdonaldtrump`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "test-2ax",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert 2000 <= len(trump_tweets) <= 4000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "2ax-move-on",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "If the assert statement above works, then continue on to question 2b."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q2b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1\n",
    "\n",
    "We are limited to how many tweets we can download.  In what month is the oldest tweet from Trump?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "oldest-month-question",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Enter the number of the month of the oldest tweet (e.g. 1 for January)\n",
    "### BEGIN SOLUTION\n",
    "oldest_month = ... #TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "oldest-month-answer",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN HIDDEN TESTS\n",
    "assert oldest_month > 9\n",
    "assert oldest_month < 12\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "\n",
    "**IMPORTANT! PLEASE READ**\n",
    "\n",
    "What if we want to access Donald Trump's old tweets? <br>\n",
    "Unfortunately, you cannot download old tweets using the public Twitter APIs.  Fortunately, we have a snapshot of earlier tweets of Donald Trump that we can combine with the newer data that you downloaded   \n",
    "\n",
    "We will again use the `fetch_and_cache` utility to download the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "download-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "from utils import fetch_and_cache\n",
    "data_url = 'https://cims.nyu.edu/~policast/old_trump_tweets.json.zip'\n",
    "file_name = 'old_trump_tweets.json.zip'\n",
    "\n",
    "dest_path = fetch_and_cache(data_url=data_url, file=file_name)\n",
    "print(f'Located at {dest_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loading-data-inst",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Finally, we we will load the tweets directly from the compressed file without decompressing it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loading-old-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "my_zip = zipfile.ZipFile(dest_path, 'r')\n",
    "with my_zip.open(\"old_trump_tweets.json\", \"r\") as f:\n",
    "    old_trump_tweets = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "formatting-note",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "This data is formatted identically to the recent tweets we just downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "pprint-old-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "pprint(old_trump_tweets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "listing-keys-inst",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "As a dictionary we can also list the keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "listing-keys",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "old_trump_tweets[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're giving you a zipfile of old tweets, you may wonder why we didn't just give you a zipfile of ALL tweets and save you the trouble of creating a Twitter developer account. The reason is that we wanted you to see what it's like to collect data from the real world on your own. It can be a pain!\n",
    "\n",
    "And for those of you that never got your developer accounts, you can see it can be even more of a pain that we expected. Sorry to anybody that wasted a bunch of time trying to get things working."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Merge the `old_trump_tweets` and the `trump_tweets` we downloaded from twitter into one giant list of tweets. \n",
    "\n",
    "**Important:** There may be some overlap so be sure to eliminate duplicate tweets.  \n",
    "**Hint:** the `id` of a tweet is always unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "all_tweets = ... #TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q3a-test",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(all_tweets) > len(trump_tweets)\n",
    "assert len(all_tweets) > len(old_trump_tweets)\n",
    "### BEGIN HIDDEN TESTS\n",
    "assert len(set([t['id'] for t in all_tweets])) <= len([t['id'] for t in all_tweets])\n",
    "### END HIDDEN TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Construct a DataFrame called `trump` containing all the tweets stored in `all_tweets`. The index of the dataframe should be the ID of each tweet (looks something like `907698529606541312`). It should have these columns:\n",
    "\n",
    "- `time`: The time the tweet was created encoded as a datetime object. (Use `pd.to_datetime` to encode the timestamp.)\n",
    "- `source`: The source device of the tweet.\n",
    "- `text`: The text of the tweet.\n",
    "- `retweet_count`: The retweet count of the tweet. \n",
    "\n",
    "Finally, **the resulting dataframe should be sorted by the index.**\n",
    "\n",
    "**Warning:** *Some tweets will store the text in the `text` field and other will use the `full_text` field.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "scrolled": true,
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "trump = ...#TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q3b-tests",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q03"
    ]
   },
   "outputs": [],
   "source": [
    "assert isinstance(trump, pd.DataFrame)\n",
    "assert trump.shape[0] < 11000\n",
    "assert trump.shape[1] >= 4\n",
    "assert 831846101179314177 in trump.index\n",
    "assert 753063644578144260 in trump.index\n",
    "assert all(col in trump.columns for col in ['time', 'source', 'text', 'retweet_count'])\n",
    "# If you fail these tests, you probably tried to use __dict__ or _json to read in the tweets\n",
    "assert np.sometrue([('Twitter for iPhone' in s) for s in trump['source'].unique()])\n",
    "assert isinstance(trump['time'].dtype, pd.core.dtypes.dtypes.DatetimeTZDtype)\n",
    "assert trump['text'].dtype == np.dtype('O')\n",
    "assert trump['retweet_count'].dtype == np.dtype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "question4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 4: Tweet Source Analysis\n",
    "\n",
    "In the following questions, we are going to find out the charateristics of Trump tweets and the devices used for the tweets.\n",
    "\n",
    "First let's examine the source field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "unique-sources",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump['source'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 4a\n",
    "\n",
    "Remove the HTML tags from the source field. \n",
    "\n",
    "**Hint:** Use `trump['source'].str.replace` and your favorite regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "trump['source'] = ...#TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q4a-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone\n",
    "ELEC_DATE = datetime(2016, 11, 8, tzinfo=timezone.utc)\n",
    "INAUG_DATE = datetime(2017, 1, 20, tzinfo=timezone.utc)\n",
    "assert set(trump[(trump['time'] > ELEC_DATE) & (trump['time'] < INAUG_DATE) ]['source'].unique()) == set(['Twitter Ads',\n",
    " 'Twitter Web Client',\n",
    " 'Twitter for Android',\n",
    " 'Twitter for iPhone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "note-about-device-usage",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We can see in the following plot that there are two device types that are more commonly used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "device-usage-plot",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump['source'].value_counts().plot(kind=\"bar\")\n",
    "plt.ylabel(\"Number of Tweets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 4b\n",
    "\n",
    "\n",
    "Is there a difference between his Tweet behavior across these devices? We will attempt to answer this question in our subsequent analysis.\n",
    "\n",
    "First, we'll take a look at whether Trump's tweets from an Android come at different times than his tweets from an iPhone. Note that Twitter gives us his tweets in the [UTC timezone](https://www.wikiwand.com/en/List_of_UTC_time_offsets) (notice the `+0000` in the first few tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "tweet-created-at",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "for t in trump_tweets[0:3]:\n",
    "    print(t['created_at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "convert-to-est-justification",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "We'll convert the tweet times to US Eastern Time, the timezone of New York and Washington D.C., since those are the places we would expect the most tweet activity from Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "convert-to-est",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "trump['est_time'] = (\n",
    "    trump['time'].dt.tz_convert(\"EST\") # Convert to Eastern Time\n",
    "    # If your data frame is, for some reason, not timezone-aware\n",
    "    # you might need the below two lines instead:\n",
    "    #  trump['time'].dt.tz_localize(\"UTC\") # Set initial timezone to UTC\n",
    "    # .trump['time'].dt.tz_convert(\"EST\") # Convert to Eastern Time\n",
    ")\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "need-to-do",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "**What you need to do:**\n",
    "\n",
    "Add a column called `hour` to the `trump` table which contains the hour of the day as floating point number computed by:\n",
    "\n",
    "$$\n",
    "\\text{hour} + \\frac{\\text{minute}}{60} + \\frac{\\text{second}}{60^2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "trump['hour'] = ... #TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q4b-tests",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q04a"
    ]
   },
   "outputs": [],
   "source": [
    "assert np.isclose(trump.loc[690171032150237184]['hour'], 8.93639)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4c",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 4c\n",
    "\n",
    "Use this data along with the seaborn `distplot` function to examine the distribution over hours of the day in eastern time that trump tweets on each device for the 2 most commonly used devices.  Your plot should look similar to the following. \n",
    "\n",
    "<img src=\"images/device_hour2.png\" width=\"600px\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q4c-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### make your plot here\n",
    "### BEGIN SOLUTION\n",
    "#TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q4d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "\n",
    "## Question 4d\n",
    "\n",
    "According to [this Verge article](https://www.theverge.com/2017/3/29/15103504/donald-trump-iphone-using-switched-android), Donald Trump switched from an Android to an iPhone sometime in March 2017.\n",
    "\n",
    "Create a figure identical to your figure from 4c, except that you should show the results only from 2016. If you get stuck consider looking at the `year_fraction` function from the next problem.\n",
    "\n",
    "During the campaign, it was theorized that Donald Trump's tweets from Android were written by him personally, and the tweets from iPhone were from his staff. Does your figure give support to this theory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9d60149ec24272e3",
     "locked": false,
     "points": 0,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### make your plot here\n",
    "### BEGIN SOLUTION\n",
    "#TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q4d-answer",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "Yes, our figure shows that the Android tweets were typically very late at night when Donald Trump is known to tweet, and when paid staff are unlikely to be posting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 5\n",
    "\n",
    "Let's now look at which device he has used over the entire time period of this dataset.\n",
    "\n",
    "To examine the distribution of dates we will convert the date to a fractional year that can be plotted as a distribution.\n",
    "\n",
    "(Code borrowed from https://stackoverflow.com/questions/6451655/python-how-to-convert-datetime-dates-to-decimal-years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "fractional-year",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "def year_fraction(date):\n",
    "    start = datetime.date(date.year, 1, 1).toordinal()\n",
    "    year_length = datetime.date(date.year+1, 1, 1).toordinal() - start\n",
    "    return date.year + float(date.toordinal() - start) / year_length\n",
    "\n",
    "\n",
    "trump['year'] = trump['time'].apply(year_fraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q5a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Use the `sns.distplot` to overlay the distributions of the 2 most frequently used web technologies over the years.  Your final plot should look like:\n",
    "\n",
    "<img src=\"images/source_years.png\" width=\"600px\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q5a-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "#TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 6: Sentiment Analysis\n",
    "\n",
    "It turns out that we can use the words in Trump's tweets to calculate a measure of the sentiment of the tweet. For example, the sentence \"I love America!\" has positive sentiment, whereas the sentence \"I hate taxes!\" has a negative sentiment. In addition, some words have stronger positive / negative sentiment than others: \"I love America.\" is more positive than \"I like America.\"\n",
    "\n",
    "We will use the [VADER (Valence Aware Dictionary and sEntiment Reasoner)](https://github.com/cjhutto/vaderSentiment) lexicon to analyze the sentiment of Trump's tweets. VADER is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media which is great for our usage.\n",
    "\n",
    "The VADER lexicon gives the sentiment of individual words. Run the following cell to show the first few rows of the lexicon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "head-vader",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "withdrawal\t0.1\t1.57797\t[1, -1, 0, -2, -2, 2, -1, 1, 0, 3]\n",
      "woe\t-1.8\t0.6\t[-3, -2, -2, -2, -1, -1, -2, -1, -2, -2]\n",
      "woebegone\t-2.6\t0.66332\t[-3, -2, -3, -2, -2, -4, -3, -2, -2, -3]\n",
      "woebegoneness\t-1.1\t1.37477\t[-3, 0, -1, 1, -1, -4, 0, -1, -1, -1]\n",
      "woeful\t-1.9\t0.83066\t[-1, -2, -2, -1, -3, -3, -1, -2, -1, -3]\n",
      "woefully\t-1.7\t1.48661\t[-1, -3, -2, 1, -3, -3, -2, -2, 1, -3]\n",
      "woefulness\t-2.1\t0.7\t[-3, -2, -2, -1, -2, -3, -3, -1, -2, -2]\n",
      "woes\t-1.9\t0.83066\t[-2, -2, -2, -1, -2, -3, -3, 0, -2, -2]\n",
      "woesome\t-1.2\t1.6\t[-2, -3, -2, -1, 0, 3, -2, -2, -1, -2]\n",
      "won\t2.7\t0.9\t[3, 4, 2, 2, 2, 4, 4, 2, 2, 2]\n",
      "wonderful\t2.7\t0.78102\t[2, 3, 3, 2, 4, 2, 2, 3, 4, 2]\n",
      "wonderfully\t2.9\t0.83066\t[1, 3, 3, 4, 3, 2, 3, 3, 4, 3]\n",
      "wonderfulness\t2.9\t0.53852\t[3, 2, 3, 3, 3, 3, 3, 2, 4, 3]\n",
      "woo\t2.1\t1.37477\t[4, 2, 1, 3, 2, 2, -1, 2, 2, 4]\n",
      "woohoo\t2.3\t1.1\t[3, 3, 1, 4, 4, 2, 1, 1, 2, 2]\n",
      "woot\t1.8\t1.07703\t[2, 0, 2, 2, 2, 2, 0, 4, 2, 2]\n",
      "worn\t-1.2\t0.4\t[-1, -1, -1, -1, -1, -1, -2, -1, -2, -1]\n",
      "worried\t-1.2\t0.74833\t[-1, -1, -1, -1, -1, -2, -3, 0, -1, -1]\n",
      "worriedly\t-2.0\t0.44721\t[-2, -2, -3, -2, -2, -2, -2, -1, -2, -2]\n",
      "worrier\t-1.8\t0.6\t[-2, -2, -1, -2, -1, -3, -2, -2, -1, -2]\n",
      "worriers\t-1.7\t0.45826\t[-2, -1, -2, -2, -2, -2, -1, -2, -1, -2]\n",
      "worries\t-1.8\t0.6\t[-2, -2, -1, -2, -1, -2, -2, -3, -1, -2]\n",
      "worriment\t-1.5\t0.67082\t[-1, -2, -1, -1, -1, -2, -1, -3, -1, -2]\n",
      "worriments\t-1.9\t0.7\t[-2, -1, -2, -3, -1, -2, -3, -1, -2, -2]\n",
      "worrisome\t-1.7\t0.64031\t[-1, -1, -1, -2, -1, -2, -3, -2, -2, -2]\n",
      "worrisomely\t-2.0\t0.63246\t[-1, -2, -1, -2, -2, -3, -2, -2, -3, -2]\n",
      "worrisomeness\t-1.9\t0.53852\t[-2, -2, -3, -1, -2, -2, -2, -1, -2, -2]\n",
      "worrit\t-2.1\t0.53852\t[-2, -2, -1, -2, -2, -3, -3, -2, -2, -2]\n",
      "worrits\t-1.2\t0.9798\t[-1, -2, -2, -1, 0, 0, -1, -3, 0, -2]\n",
      "worry\t-1.9\t0.7\t[-2, -3, -1, -3, -1, -2, -1, -2, -2, -2]\n",
      "worrying\t-1.4\t0.66332\t[-2, -1, -2, -2, -1, 0, -1, -1, -2, -2]\n",
      "worrywart\t-1.8\t0.9798\t[-2, -2, -2, -1, -1, -1, -1, -3, -1, -4]\n",
      "worrywarts\t-1.5\t0.5\t[-2, -1, -2, -2, -2, -1, -1, -1, -2, -1]\n",
      "worse\t-2.1\t0.83066\t[-2, -2, -1, -3, -4, -2, -1, -2, -2, -2]\n",
      "worsen\t-2.3\t0.78102\t[-4, -3, -1, -2, -2, -2, -2, -3, -2, -2]\n",
      "worsened\t-1.9\t1.22066\t[-2, -2, -2, -1, -2, -2, -4, 1, -3, -2]\n",
      "worsening\t-2.0\t0.44721\t[-2, -3, -2, -2, -2, -2, -1, -2, -2, -2]\n",
      "worsens\t-2.1\t0.53852\t[-2, -2, -2, -2, -1, -2, -2, -3, -3, -2]\n",
      "worser\t-2.0\t0.89443\t[-2, -2, -4, -1, -2, -2, -2, -3, -1, -1]\n",
      "worship\t1.2\t1.07703\t[1, 0, 0, 1, 3, 0, 2, 3, 1, 1]\n",
      "worshiped\t2.4\t1.0198\t[1, 2, 4, 3, 4, 1, 2, 3, 2, 2]\n",
      "worshiper\t1.0\t1.0\t[0, 0, 2, 3, 0, 2, 1, 1, 1, 0]\n",
      "worshipers\t0.9\t0.83066\t[0, 0, 0, 2, 1, 1, 1, 2, 2, 0]\n",
      "worshipful\t0.7\t1.00499\t[1, -1, 3, 1, 1, 1, 0, 0, 0, 1]\n",
      "worshipfully\t1.1\t1.3\t[0, 0, 0, 1, 3, 0, 3, 3, 1, 0]\n",
      "worshipfulness\t1.6\t0.8\t[3, 1, 2, 2, 1, 1, 3, 1, 1, 1]\n",
      "worshiping\t1.0\t1.18322\t[0, 3, 0, 3, 0, 1, 1, 2, 0, 0]\n",
      "worshipless\t-0.6\t1.0198\t[0, -1, -3, -1, -1, -1, 0, 0, 0, 1]\n",
      "worshipped\t2.7\t0.78102\t[3, 2, 3, 3, 1, 4, 2, 3, 3, 3]\n",
      "worshipper\t0.6\t0.66332\t[1, 1, 0, 0, 1, 0, 0, 2, 1, 0]\n",
      "worshippers\t0.8\t0.87178\t[0, 1, 0, 0, 3, 1, 1, 1, 0, 1]\n",
      "worshipping\t1.6\t1.28062\t[1, 3, 3, 3, 0, 3, 1, 0, 2, 0]\n",
      "worships\t1.4\t1.11355\t[2, 0, 1, 3, 2, 1, 0, 3, 2, 0]\n",
      "worst\t-3.1\t1.04403\t[-4, -4, -3, -1, -3, -4, -2, -2, -4, -4]\n",
      "worth\t0.9\t0.9434\t[0, 0, 1, 1, 2, 1, 1, 3, 0, 0]\n",
      "worthless\t-1.9\t1.13578\t[-3, -1, -3, -4, -1, -3, -1, -1, -1, -1]\n",
      "worthwhile\t1.4\t0.4899\t[1, 1, 1, 2, 1, 1, 2, 1, 2, 2]\n",
      "worthy\t1.9\t0.53852\t[2, 2, 2, 1, 1, 2, 2, 2, 3, 2]\n",
      "wow\t2.8\t0.9798\t[2, 3, 2, 4, 4, 3, 3, 2, 1, 4]\n",
      "wowed\t2.6\t0.8\t[3, 3, 4, 3, 2, 1, 3, 3, 2, 2]\n",
      "wowing\t2.5\t0.67082\t[2, 2, 3, 3, 2, 3, 4, 2, 2, 2]\n",
      "wows\t2.0\t1.61245\t[2, 3, 3, 3, 2, 1, -2, 1, 4, 3]\n",
      "wowser\t-1.1\t2.02237\t[-3, 3, 0, 2, -2, -1, -3, -2, -2, -3]\n",
      "wowsers\t1.0\t2.14476\t[0, -2, 4, 2, 3, 0, 1, 2, -3, 3]\n",
      "wrathful\t-2.7\t0.64031\t[-3, -2, -2, -3, -3, -2, -4, -2, -3, -3]\n",
      "wreck\t-1.9\t0.7\t[-1, -2, -3, -3, -2, -2, -2, -1, -1, -2]\n",
      "wrong\t-2.1\t1.04403\t[-2, -2, -2, -2, -4, -4, -1, -1, -1, -2]\n",
      "wronged\t-1.9\t0.53852\t[-2, -2, -2, -2, -2, -1, -3, -2, -2, -1]\n",
      "x-d\t2.6\t0.91652\t[2, 3, 3, 4, 1, 2, 3, 4, 2, 2]\n",
      "x-p\t1.7\t0.45826\t[2, 2, 1, 2, 2, 1, 1, 2, 2, 2]\n",
      "xd\t2.8\t0.87178\t[3, 3, 4, 2, 3, 3, 1, 2, 4, 3]\n",
      "xp\t1.6\t0.4899\t[2, 2, 2, 1, 1, 1, 2, 2, 1, 2]\n",
      "yay\t2.4\t1.0198\t[1, 3, 3, 2, 2, 1, 4, 4, 2, 2]\n",
      "yeah\t1.2\t0.6\t[1, 1, 1, 2, 1, 1, 0, 2, 1, 2]\n",
      "yearning\t0.5\t1.0247\t[0, 1, 0, 1, 0, 3, 0, 1, -1, 0]\n",
      "yeees\t1.7\t1.00499\t[1, 3, 1, 2, 1, 1, 4, 2, 1, 1]\n",
      "yep\t1.2\t0.4\t[1, 1, 1, 1, 1, 1, 2, 2, 1, 1]\n",
      "yes\t1.7\t0.78102\t[1, 2, 2, 1, 1, 1, 3, 3, 1, 2]\n",
      "youthful\t1.3\t0.45826\t[1, 2, 1, 2, 1, 1, 1, 1, 2, 1]\n",
      "yucky\t-1.8\t0.6\t[-2, -1, -1, -2, -2, -1, -2, -2, -3, -2]\n",
      "yummy\t2.4\t1.0198\t[1, 2, 4, 3, 2, 2, 3, 1, 4, 2]\n",
      "zealot\t-1.9\t1.04403\t[-2, -3, -1, -2, -1, -3, -4, -1, -1, -1]\n",
      "zealots\t-0.8\t1.83303\t[-1, -2, -1, -2, -2, 1, -2, 4, -1, -2]\n",
      "zealous\t0.5\t1.43178\t[2, -1, 2, 1, 0, 0, 3, 0, -2, 0]\n",
      "{:\t1.8\t0.9798\t[1, 3, 2, 2, 1, 1, 4, 2, 1, 1]\n",
      "|-0\t-1.2\t0.74833\t[0, -2, -1, -1, -1, -1, -1, -1, -1, -3]\n",
      "|-:\t-0.8\t0.74833\t[-1, -2, 0, -1, 0, -2, -1, -1, 0, 0]\n",
      "|-:>\t-1.6\t0.4899\t[-1, -2, -2, -2, -2, -1, -1, -2, -2, -1]\n",
      "|-o\t-1.2\t0.9798\t[-1, 0, -1, -1, -1, -1, -1, -4, -1, -1]\n",
      "|:\t-0.5\t1.68819\t[2, -3, -1, 0, -1, -1, -1, -2, -1, 3]\n",
      "|;-)\t2.2\t1.32665\t[4, 1, 1, 1, 3, 2, 4, 1, 4, 1]\n",
      "|=\t-0.4\t1.56205\t[2, -2, -1, 0, -1, -1, -1, -2, -1, 3]\n",
      "|^:\t-1.1\t0.7\t[-2, 0, -1, -1, 0, -1, -1, -2, -2, -1]\n",
      "|o:\t-0.9\t0.53852\t[-1, 0, -1, -2, -1, 0, -1, -1, -1, -1]\n",
      "||-:\t-2.3\t0.45826\t[-2, -2, -2, -3, -3, -3, -2, -2, -2, -2]\n",
      "}:\t-2.1\t0.83066\t[-1, -1, -3, -2, -3, -2, -2, -1, -3, -3]\n",
      "}:(\t-2.0\t0.63246\t[-3, -1, -2, -1, -3, -2, -2, -2, -2, -2]\n",
      "}:)\t0.4\t1.42829\t[1, 1, -2, 1, 2, -2, 1, -1, 2, 1]\n",
      "}:-(\t-2.1\t0.7\t[-2, -1, -2, -2, -2, -4, -2, -2, -2, -2]\n",
      "}:-)\t0.3\t1.61555\t[1, 1, -2, 1, -1, -3, 2, 2, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(''.join(open(\"vader_lexicon.txt\").readlines()[-100:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 6a\n",
    "\n",
    "As you can see, the lexicon contains emojis too! The first column of the lexicon is the *token*, or the word itself. The second column is the *polarity* of the word, or how positive / negative it is.\n",
    "\n",
    "(How did they decide the polarities of these words? What are the other two columns in the lexicon? See the link above.)\n",
    "\n",
    " Read in the lexicon into a DataFrame called `sent`. The index of the DF should be the tokens in the lexicon. `sent` should have one column: `polarity`: The polarity of each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a1",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "sent = ...#TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6a-test1",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q05a"
    ]
   },
   "outputs": [],
   "source": [
    "assert isinstance(sent, pd.DataFrame)\n",
    "assert sent.shape == (7517, 1)\n",
    "assert list(sent.index[5000:5005]) == ['paranoids', 'pardon', 'pardoned', 'pardoning', 'pardons']\n",
    "assert np.allclose(sent['polarity'].head(), [-1.5, -0.4, -1.5, -0.4, -0.7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 6b\n",
    "\n",
    "Now, let's use this lexicon to calculate the overall sentiment for each of Trump's tweets. Here's the basic idea:\n",
    "\n",
    "1. For each tweet, find the sentiment of each word.\n",
    "2. Calculate the sentiment of each tweet by taking the sum of the sentiments of its words.\n",
    "\n",
    "First, let's lowercase the text in the tweets since the lexicon is also lowercase. Set the `text` column of the `trump` DF to be the lowercased text of each tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6b-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "#TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6b-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q05b"
    ]
   },
   "outputs": [],
   "source": [
    "assert trump['text'].loc[884740553040175104] == 'working hard to get the olympics for the united states (l.a.). stay tuned!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6c-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 6c\n",
    "\n",
    "Now, let's get rid of punctuation since it'll cause us to fail to match words. Create a new column called `no_punc` in the `trump` DF to be the lowercased text of each tweet with all punctuation replaced by a single space. We consider punctuation characters to be any character that isn't a Unicode word character or a whitespace character. You may want to consult the Python documentation on regexes for this problem.\n",
    "\n",
    "(Why don't we simply remove punctuation instead of replacing with a space? See if you can figure this out by looking at the tweet data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6c",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "# Save your regex in punct_re\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "#TODO\n",
    "punct_re = r''\n",
    "trump['no_punc'] = ...\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6c-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q05c"
    ]
   },
   "outputs": [],
   "source": [
    "assert isinstance(punct_re, str)\n",
    "assert re.search(punct_re, 'this') is None\n",
    "assert re.search(punct_re, 'this is ok') is None\n",
    "assert re.search(punct_re, 'this is\\nok') is None\n",
    "assert re.search(punct_re, 'this is not ok.') is not None\n",
    "assert re.search(punct_re, 'this#is#ok') is not None\n",
    "assert re.search(punct_re, 'this^is ok') is not None\n",
    "assert trump['no_punc'].loc[800329364986626048] == 'i watched parts of  nbcsnl saturday night live last night  it is a totally one sided  biased show   nothing funny at all  equal time for us '\n",
    "assert trump['no_punc'].loc[894620077634592769] == 'on  purpleheartday i thank all the brave men and women who have sacrificed in battle for this great nation   usa   https   t co qmfdlslp6p'\n",
    "# If you fail these tests, you accidentally changed the text column\n",
    "assert trump['text'].loc[884740553040175104] == 'working hard to get the olympics for the united states (l.a.). stay tuned!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6d-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 6d:\n",
    "\n",
    "\n",
    "Now, let's convert the tweets into what's called a [*tidy format*](https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html) to make the sentiments easier to calculate. Use the `no_punc` column of `trump` to create a table called `tidy_format`. The index of the table should be the IDs of the tweets, repeated once for every word in the tweet. It has two columns:\n",
    "\n",
    "1. `num`: The location of the word in the tweet. For example, if the tweet was \"i love america\", then the location of the word \"i\" is 0, \"love\" is 1, and \"america\" is 2.\n",
    "2. `word`: The individual words of each tweet.\n",
    "\n",
    "The first few rows of our `tidy_format` table look like:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>num</th>\n",
    "      <th>word</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>0</td>\n",
    "      <td>i</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>1</td>\n",
    "      <td>think</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>2</td>\n",
    "      <td>senator</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>3</td>\n",
    "      <td>blumenthal</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>894661651760377856</th>\n",
    "      <td>4</td>\n",
    "      <td>should</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "**Note that you'll get different results depending on when you pulled in the tweets.** However, you can double check that your tweet with ID `894661651760377856` has the same rows as ours. Our tests don't check whether your table looks exactly like ours.\n",
    "\n",
    "As usual, try to avoid using any for loops. Our solution uses a chain of 5 methods on the 'trump' DF, albeit using some rather advanced Pandas hacking.\n",
    "\n",
    "* **Hint 1:** Try looking at the `expand` argument to pandas' `str.split`.\n",
    "\n",
    "* **Hint 2:** Try looking at the `stack()` method.\n",
    "\n",
    "* **Hint 3:** Try looking at the `level` parameter of the `reset_index` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6d-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "tidy_format = ...#TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6d-tests",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q05d"
    ]
   },
   "outputs": [],
   "source": [
    "assert tidy_format.loc[894661651760377856].shape == (27, 2)\n",
    "assert ' '.join(list(tidy_format.loc[894661651760377856]['word'])) == 'i think senator blumenthal should take a nice long vacation in vietnam where he lied about his service so he can at least say he was there'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6e-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 6e:\n",
    "\n",
    "Now that we have this table in the tidy format, it becomes much easier to find the sentiment of each tweet: we can join the table with the lexicon table. \n",
    "\n",
    "Add a `polarity` column to the `trump` table.  The `polarity` column should contain the sum of the sentiment polarity of each word in the text of the tweet.\n",
    "\n",
    "**Hint** you will need to merge the `tidy_format` and `sent` tables and group the final answer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6e",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "trump['polarity'] = ...#TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6e-tests",
     "locked": true,
     "points": 2,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q05e"
    ]
   },
   "outputs": [],
   "source": [
    "assert np.allclose(trump.loc[744701872456536064, 'polarity'], 8.4)\n",
    "assert np.allclose(trump.loc[745304731346702336, 'polarity'], 2.5)\n",
    "assert np.allclose(trump.loc[744519497764184064, 'polarity'], 1.7)\n",
    "assert np.allclose(trump.loc[894661651760377856, 'polarity'], 0.2)\n",
    "assert np.allclose(trump.loc[894620077634592769, 'polarity'], 5.4)\n",
    "# If you fail this test, you dropped tweets with 0 polarity\n",
    "assert np.allclose(trump.loc[744355251365511169, 'polarity'], 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "a-note-on-vader",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Now we have a measure of the sentiment of each of his tweets! Note that this calculation is rather basic; you can read over the VADER readme to understand a more robust sentiment analysis.\n",
    "\n",
    "Now, run the cells below to see the most positive and most negative tweets from Trump in your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "negative-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "print('Most negative tweets:')\n",
    "for t in trump.sort_values('polarity').head()['text']:\n",
    "    print('\\n  ', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "postive-tweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Most positive tweets:')\n",
    "for t in trump.sort_values('polarity', ascending=False).head()['text']:\n",
    "    print('\\n  ', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q6g",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 6g\n",
    "\n",
    "Plot the distribution of tweet sentiments broken down by whether the text of the tweet contains `nyt` or `fox`.  Then in the box below comment on what we observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6g-answer",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "#TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "comment-on-faux-news",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "#### Comment on what you observe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q6g-written",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    }
   },
   "source": [
    "We notice that the president appears to say more positive things about Fox than the \n",
    "New York Times.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tidy_format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7-header",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 7: Engagement\n",
    "\n",
    "## Question 7a\n",
    "\n",
    "In this problem, we'll explore which words led to a greater average number of retweets. For example, at the time of this writing, Donald Trump has two tweets that contain the word 'oakland' (tweets 932570628451954688 and 1016609920031117312) with 36757 and 10286 retweets respectively, for an average of 23,521.5.\n",
    "\n",
    "Find the top 20 most retweeted words. Include only words that appear in at least 25 tweets. As usual, try to do this without any for loops. You can string together ~7 pandas commands and get everything done on one line.\n",
    "\n",
    "Your `top_20` table should have this format:\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th></th>\n",
    "      <th>retweet_count</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>word</th>\n",
    "      <th></th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <th>jong</th>\n",
    "      <td>40675.666667</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>try</th>\n",
    "      <td>33937.800000</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>kim</th>\n",
    "      <td>32849.595745</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>un</th>\n",
    "      <td>32741.731707</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <th>maybe</th>\n",
    "      <td>30473.192308</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "\n",
    "Note that the contents of the table may be different based on how many tweets you pulled and when you did so; focus on the format, not the numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7a",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "top_20 = ... #TODO\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q7a-test",
     "locked": true,
     "points": 1,
     "schema_version": 2,
     "solution": false
    },
    "tags": [
     "test",
     "q07a"
    ]
   },
   "outputs": [],
   "source": [
    "# Although it can't be guaranteed, it's very likely that some of these words will be in the top 20\n",
    "# Although this may vary depending on when exactly you pulled your data:\n",
    "assert 'un'     in top_20.index\n",
    "assert 'nuclear' in top_20.index\n",
    "assert 'old'    in top_20.index\n",
    "assert 'nfl'    in top_20.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "bar-chart-results",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "Here's a bar chart of your results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "top-retweets",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "top_20['retweet_count'].sort_values().plot.barh(figsize=(10, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q7b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 7b\n",
    "\n",
    "At some point in time, \"kim\", \"jong\" and \"un\" were apparently really popular in Trump's tweets! It seems like we can conclude that his tweets involving jong are more popular than his other tweets. Or can we?\n",
    "\n",
    "Consider each of the statements about possible confounding factors below. State whether each statement is true or false and explain. If the statement is true, state whether the confounding factor could have made kim jong un related tweets higher in the list than they should be.\n",
    "\n",
    "1. We didn't restrict our word list to nouns, so we have unhelpful words like \"let\" and \"any\" in our result.\n",
    "1. We didn't remove hashtags in our text, so we have duplicate words (eg. #great and great).\n",
    "1. We didn't account for the fact that Trump's follower count has increased over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q7b-answer",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written"
    ]
   },
   "source": [
    "\n",
    "1. True. However, this will not cause \"kim\", \"jong\" and \"un\" to top the list of retweeted\n",
    "words since restricting to nouns does not affect the count of the retweets containing \"kim\", \"jong\" and \"un\".\n",
    "2. False. We removed hashtags in our text when we removed punctuation.\n",
    "3. True. This could indeed cause \"kim\", \"jong\" and \"un\" to appear higher on the list than it should have.\n",
    "If his follower count increased over time, we would expect the number of retweets over time\n",
    "to increase as well, regardless of what words are in the tweets. If he just started using the\n",
    "term \"fake news\" recently, it's likely that those tweets would get more retweets just because\n",
    "he had more followers than before.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q8",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Question 8\n",
    "\n",
    "Using the `trump` tweets construct an interesting plot describing a property of the data and discuss what you found below.\n",
    "\n",
    "**Ideas:**\n",
    "\n",
    "1. How has the sentiment changed with length of the tweets?\n",
    "1. Does sentiment affect retweet count?\n",
    "1. Are retweets more negative than regular tweets?\n",
    "1. Are there any spikes in the number of retweets and do the correspond to world events? \n",
    "1. *Bonus:* How many Russian twitter bots follow Trump? \n",
    "1. What terms have an especially positive or negative sentiment?\n",
    "\n",
    "You can look at other data sources and even tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "plot8-q",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q8-plot",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "disc8-q",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Discussion of Your Plot:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "q8-disc",
     "locked": false,
     "points": 1,
     "schema_version": 2,
     "solution": true
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "submission",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## Submission\n",
    "\n",
    "Congrats, you just finished Project 1!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
